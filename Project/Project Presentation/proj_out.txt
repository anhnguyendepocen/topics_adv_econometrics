>> project_test
 
 ----------------------------- 
    Test Training Algorithms   
 ----------------------------- 
 
    Algorithm     Error_int    Error_test     Time  
    __________    _________    __________    _______

    'trainrp'      0.70211     0.717          5.5384
    'trainscg'    0.070556     0.099          20.089
    'traincgb'    0.072111     0.102          28.357
    'traincgf'     0.10089     0.123          33.485
    'traincgp'    0.069667     0.099          36.416
    'trainoss'     0.15922     0.173          48.149
    'traingdx'     0.32044     0.328          4.2746
    'traingdm'     0.89878     0.886         0.57124
    'traingd'      0.45789     0.442          25.565

 
 
 ----------------------------- 
       MNIST - PCA + ANN       
 ----------------------------- 
 
    PCA_Size    NN_Architecture    Error_int    Error_test
    ________    _______________    _________    __________

     10         [        10]          0.213     0.827     
     10         [        25]        0.13933     0.813     
     10         [       100]        0.10644     0.774     
     10         [1×2 double]        0.12822     0.766     
     10         [1×3 double]          0.136     0.764     
     10         [1×3 double]       0.087778     0.776     
     25         [        10]        0.11711     0.708     
     25         [        25]       0.090667     0.712     
     25         [       100]       0.037778     0.752     
     25         [1×2 double]       0.076889     0.797     
     25         [1×3 double]          0.069     0.761     
     25         [1×3 double]       0.029889     0.747     
     50         [        10]       0.092111     0.744     
     50         [        25]          0.065     0.729     
     50         [       100]       0.030333      0.81     
     50         [1×2 double]          0.054     0.822     
     50         [1×3 double]           0.12     0.745     
     50         [1×3 double]       0.044444     0.792     
    100         [        10]       0.082333     0.739     
    100         [        25]       0.060333     0.693     
    100         [       100]       0.025444     0.761     
    100         [1×2 double]       0.047778      0.78     
    100         [1×3 double]       0.048444       0.8     
    100         [1×3 double]       0.046556     0.714

----------------------------- 
       MNIST - PCA + ANN       
 ----------------------------- 
 
    PCA_Size    NN_Architecture    Error_int    Error_test
    ________    _______________    _________    __________

     11         [        10]        0.18933     0.748     
     11         [        25]        0.16856     0.698     
     11         [       100]          0.105     0.757     
     11         [1×2 double]        0.12622     0.771     
     11         [1×3 double]        0.11911     0.838     
     11         [1×3 double]       0.079444     0.807
     
     33         [        10]        0.10111     0.741     
     33         [        25]       0.088333     0.729     
     33         [       100]          0.037     0.817     
     33         [1×2 double]       0.051444     0.756     
     33         [1×3 double]       0.055667     0.787     
     33         [1×3 double]       0.037222     0.815 
    
     58         [        10]       0.084778     0.705     
     58         [        25]       0.067444     0.724     
     58         [       100]       0.029556     0.746     
     58         [1×2 double]          0.056      0.77     
     58         [1×3 double]       0.066444     0.807     
     58         [1×3 double]       0.043333     0.782 
    
    150         [        10]       0.071111     0.723     
    150         [        25]          0.054     0.688     
    150         [       100]       0.025889     0.768     
    150         [1×2 double]       0.051778      0.79     
    150         [1×3 double]       0.065667      0.83     
    150         [1×3 double]       0.049556     0.852      

 
 
 ----------------------------- 
      notMNIST - PCA + ANN     
        [ 2D_FFT = 0 ]         
 ----------------------------- 
 
    PCA_Size    NN_Architecture    Error_int    Error_test
    ________    _______________    _________    __________

     10         [        10]        0.18533     0.592     
     10         [        25]        0.16211     0.566     
     10         [       100]          0.138     0.525     
     10         [1×2 double]        0.14211      0.57     
     10         [1×3 double]        0.13844     0.585     
     10         [1×3 double]        0.11522     0.568     
     25         [        10]        0.13056     0.596     
     25         [        25]        0.11433     0.592     
     25         [       100]       0.089111     0.597     
     25         [1×2 double]        0.10222     0.556     
     25         [1×3 double]        0.10056       0.6     
     25         [1×3 double]       0.097333     0.604     
     50         [        10]          0.125     0.612     
     50         [        25]       0.089667      0.59     
     50         [       100]       0.064778      0.59     
     50         [1×2 double]       0.081889      0.58     
     50         [1×3 double]          0.096     0.575     
     50         [1×3 double]       0.064667     0.626     
    100         [        10]        0.11733     0.601     
    100         [        25]           0.09     0.584     
    100         [       100]       0.052778     0.582     
    100         [1×2 double]       0.081111     0.583     
    100         [1×3 double]           0.08     0.615     
    100         [1×3 double]       0.076444     0.584     


----------------------------- 
      notMNIST - PCA + ANN     
        [ 2D_FFT = 0 ]         
 ----------------------------- 
 
    PCA_Size    NN_Architecture    Error_int    Error_test
    ________    _______________    _________    __________

      5         [        10]        0.31644      0.63     
      5         [        25]        0.26444     0.616     
      5         [       100]        0.23711     0.613     
      5         [1×2 double]        0.22589     0.616     
      5         [1×3 double]        0.23556     0.639     
      5         [1×3 double]        0.20733     0.612
     
     19         [        10]        0.13533      0.58     
     19         [        25]        0.12311     0.611     
     19         [       100]       0.089889     0.555     
     19         [1×2 double]            0.1     0.591     
     19         [1×3 double]        0.10456     0.642     
     19         [1×3 double]        0.10611     0.575
     
     40         [        10]          0.115     0.592     
     40         [        25]        0.10144     0.559     
     40         [       100]          0.067     0.592     
     40         [1×2 double]       0.095556      0.57     
     40         [1×3 double]        0.10022     0.584     
     40         [1×3 double]       0.094556      0.62
	     
    126         [        10]       0.093111     0.581     
    126         [        25]       0.081667      0.58     
    126         [       100]          0.053     0.585     
    126         [1×2 double]       0.081111     0.587     
    126         [1×3 double]          0.089     0.568     
    126         [1×3 double]       0.079222     0.579   


 
 ----------------------------- 
   Fashion MNIST - PCA + ANN   
        [ 2D_FFT = 1 ]         
 ----------------------------- 
 
    PCA_Size    NN_Architecture    Error_int    Error_test
    ________    _______________    _________    __________

     10         [        10]       0.26422      0.313     
     10         [        25]       0.23589      0.285     
     10         [       100]         0.219      0.275     
     10         [1×2 double]         0.256      0.294     
     10         [1×3 double]       0.26556      0.305     
     10         [1×3 double]         0.197      0.262     
     25         [        10]       0.21867      0.412     
     25         [        25]       0.19267      0.418     
     25         [       100]       0.16711      0.396     
     25         [1×2 double]       0.18922      0.436     
     25         [1×3 double]       0.19389      0.352     
     25         [1×3 double]       0.16511        0.4     
     50         [        10]       0.23622      0.443     
     50         [        25]       0.17867      0.426     
     50         [       100]       0.13622      0.417     
     50         [1×2 double]         0.192      0.426     
     50         [1×3 double]       0.21978      0.424     
     50         [1×3 double]       0.17811      0.439     
    100         [        10]       0.18622      0.457     
    100         [        25]       0.16678      0.404     
    100         [       100]       0.13711      0.414     
    100         [1×2 double]       0.16844      0.444     
    100         [1×3 double]       0.21844      0.412     
    100         [1×3 double]         0.167      0.424     

 ----------------------------- 
   Fashion MNIST - PCA + ANN   
        [ 2D_FFT = 1 ]         
 ----------------------------- 
 
    PCA_Size    NN_Architecture    Error_int    Error_test
    ________    _______________    _________    __________

     2          [        10]       0.52256      0.554     
     2          [        25]       0.50233      0.545     
     2          [       100]       0.47144      0.531     
     2          [1×2 double]       0.49811      0.516     
     2          [1×3 double]       0.48411      0.537     
     2          [1×3 double]       0.48022      0.527
     
     3          [        10]       0.38622      0.422     
     3          [        25]       0.40367      0.422     
     3          [       100]       0.35622      0.398     
     3          [1×2 double]       0.39122      0.417     
     3          [1×3 double]       0.39078       0.41     
     3          [1×3 double]       0.35622      0.403
     
     8          [        10]       0.28756      0.327     
     8          [        25]       0.24211       0.29     
     8          [       100]         0.243      0.291     
     8          [1×2 double]       0.22556      0.279     
     8          [1×3 double]       0.29611      0.323     
     8          [1×3 double]       0.22089      0.257
     
    44          [        10]       0.20144      0.412     
    44          [        25]       0.17711      0.442     
    44          [       100]         0.151      0.444     
    44          [1×2 double]       0.17978      0.399     
    44          [1×3 double]       0.21567      0.415     
    44          [1×3 double]       0.17756      0.414  

 
 
 Training:          MNIST - CNN          
 
Training on single CPU.
Initializing image normalization.
|=======================================================================================================================|
|     Epoch    |   Iteration  | Time Elapsed |  Mini-batch  |  Validation  |  Mini-batch  |  Validation  | Base Learning|
|              |              |  (seconds)   |     Loss     |     Loss     |   Accuracy   |   Accuracy   |     Rate     |
|=======================================================================================================================|
|            1 |            1 |         0.24 |       2.3014 |       2.3022 |       23.44% |       14.40% |       0.0100 |
|            1 |           50 |         1.86 |       0.7090 |       0.6244 |       76.56% |       81.50% |       0.0100 |
|            1 |          100 |         3.31 |       0.5969 |       0.4101 |       87.50% |       88.10% |       0.0100 |
|            2 |          150 |         4.78 |       0.4870 |       0.3698 |       84.38% |       89.50% |       0.0100 |
|            2 |          200 |         6.25 |       0.2144 |       0.3410 |       92.19% |       90.30% |       0.0100 |
|            2 |          250 |         7.73 |       0.2547 |       0.3167 |       93.75% |       91.10% |       0.0100 |
|            3 |          300 |         9.24 |       0.2609 |       0.2900 |       90.62% |       91.90% |       0.0100 |
|            3 |          350 |        10.70 |       0.4178 |       0.2679 |       87.50% |       92.20% |       0.0100 |
|            4 |          400 |        12.11 |       0.3049 |       0.2388 |       90.62% |       93.50% |       0.0100 |
|            4 |          450 |        13.54 |       0.1332 |       0.2308 |       95.31% |       93.70% |       0.0100 |
|            4 |          500 |        14.97 |       0.1076 |       0.2180 |       96.88% |       93.70% |       0.0100 |
|            5 |          550 |        16.60 |       0.1501 |       0.2029 |       93.75% |       94.80% |       0.0100 |
|            5 |          600 |        18.05 |       0.2568 |       0.2020 |       93.75% |       94.70% |       0.0100 |
|            6 |          650 |        19.51 |       0.1520 |       0.1883 |       95.31% |       94.70% |       0.0020 |
|            6 |          700 |        21.18 |       0.0697 |       0.1782 |       98.44% |       94.90% |       0.0020 |
|            6 |          750 |        22.65 |       0.0535 |       0.1778 |      100.00% |       95.30% |       0.0020 |
|            7 |          800 |        24.25 |       0.1090 |       0.1796 |       96.88% |       95.00% |       0.0020 |
|            7 |          850 |        25.67 |       0.1939 |       0.1759 |       96.88% |       95.70% |       0.0020 |
|            8 |          900 |        27.10 |       0.1197 |       0.1758 |       95.31% |       95.30% |       0.0020 |
|            8 |          950 |        28.47 |       0.0590 |       0.1712 |       98.44% |       95.40% |       0.0020 |
|            8 |         1000 |        29.94 |       0.0530 |       0.1720 |      100.00% |       95.50% |       0.0020 |
|            9 |         1050 |        31.72 |       0.1022 |       0.1742 |       96.88% |       95.30% |       0.0020 |
|            9 |         1100 |        33.40 |       0.1826 |       0.1715 |       96.88% |       95.90% |       0.0020 |
|           10 |         1150 |        34.81 |       0.1066 |       0.1714 |       95.31% |       95.40% |       0.0020 |
|           10 |         1200 |        36.19 |       0.0539 |       0.1668 |      100.00% |       95.60% |       0.0020 |
|           10 |         1250 |        37.62 |       0.0483 |       0.1677 |      100.00% |       95.70% |       0.0020 |
|           11 |         1300 |        39.06 |       0.0976 |       0.1682 |       96.88% |       95.70% |       0.0004 |
|           11 |         1350 |        40.48 |       0.1698 |       0.1667 |       96.88% |       95.60% |       0.0004 |
|           12 |         1400 |        41.92 |       0.0994 |       0.1669 |       95.31% |       95.60% |       0.0004 |
|           12 |         1450 |        43.34 |       0.0444 |       0.1663 |      100.00% |       95.60% |       0.0004 |
|           12 |         1500 |        44.78 |       0.0434 |       0.1663 |      100.00% |       95.70% |       0.0004 |
|           13 |         1550 |        46.22 |       0.0954 |       0.1671 |       96.88% |       95.50% |       0.0004 |
|           13 |         1600 |        47.62 |       0.1719 |       0.1660 |       96.88% |       95.70% |       0.0004 |
|           14 |         1650 |        49.04 |       0.0973 |       0.1661 |       95.31% |       95.70% |       0.0004 |
|           14 |         1700 |        50.44 |       0.0440 |       0.1655 |      100.00% |       95.50% |       0.0004 |
|           14 |         1750 |        51.82 |       0.0428 |       0.1655 |      100.00% |       95.70% |       0.0004 |
|           15 |         1800 |        53.22 |       0.0940 |       0.1663 |       96.88% |       95.60% |       0.0004 |
|           15 |         1850 |        54.59 |       0.1709 |       0.1652 |       96.88% |       95.70% |       0.0004 |
|           16 |         1900 |        56.02 |       0.0951 |       0.1651 |       95.31% |       95.60% |     8.00e-05 |
|           16 |         1950 |        57.43 |       0.0440 |       0.1650 |      100.00% |       95.60% |     8.00e-05 |
|           16 |         2000 |        58.87 |       0.0411 |       0.1650 |      100.00% |       95.60% |     8.00e-05 |
|           17 |         2050 |        60.25 |       0.0935 |       0.1651 |       96.88% |       95.70% |     8.00e-05 |
|           17 |         2100 |        61.75 |       0.1685 |       0.1650 |       96.88% |       95.60% |     8.00e-05 |
|           18 |         2150 |        63.21 |       0.0941 |       0.1650 |       95.31% |       95.60% |     8.00e-05 |
|           18 |         2200 |        64.65 |       0.0435 |       0.1649 |      100.00% |       95.60% |     8.00e-05 |
|           18 |         2250 |        66.23 |       0.0407 |       0.1649 |      100.00% |       95.70% |     8.00e-05 |
|           19 |         2300 |        67.67 |       0.0932 |       0.1650 |       96.88% |       95.80% |     8.00e-05 |
|           19 |         2350 |        69.09 |       0.1687 |       0.1649 |       96.88% |       95.80% |     8.00e-05 |
|           20 |         2400 |        70.48 |       0.0934 |       0.1649 |       95.31% |       95.70% |     8.00e-05 |
|           20 |         2450 |        71.83 |       0.0433 |       0.1648 |      100.00% |       95.60% |     8.00e-05 |
|           20 |         2500 |        73.18 |       0.0404 |       0.1648 |      100.00% |       95.80% |     8.00e-05 |
|=======================================================================================================================|
Training on single CPU.
Initializing image normalization.
|=======================================================================================================================|
|     Epoch    |   Iteration  | Time Elapsed |  Mini-batch  |  Validation  |  Mini-batch  |  Validation  | Base Learning|
|              |              |  (seconds)   |     Loss     |     Loss     |   Accuracy   |   Accuracy   |     Rate     |
|=======================================================================================================================|
|            1 |            1 |         0.07 |       2.3026 |       2.3026 |       17.19% |       12.40% |       0.0100 |
|            1 |           50 |         2.45 |       2.3018 |       2.2999 |       18.75% |       10.20% |       0.0100 |
|            1 |          100 |         4.85 |       2.3030 |       2.2938 |       12.50% |       10.20% |       0.0100 |
|            2 |          150 |         7.23 |       2.1594 |       2.1032 |       23.44% |       30.10% |       0.0100 |
|            2 |          200 |         9.63 |       0.4458 |       0.6072 |       82.81% |       80.90% |       0.0100 |
|            2 |          250 |        12.03 |       0.4923 |       0.3876 |       85.94% |       88.10% |       0.0100 |
|            3 |          300 |        14.48 |       0.2647 |       0.3044 |       93.75% |       90.90% |       0.0100 |
|            3 |          350 |        17.09 |       0.2745 |       0.2772 |       89.06% |       92.10% |       0.0100 |
|            4 |          400 |        19.75 |       0.1751 |       0.2467 |       98.44% |       92.10% |       0.0100 |
|            4 |          450 |        22.22 |       0.0995 |       0.2362 |       96.88% |       92.90% |       0.0100 |
|            4 |          500 |        24.80 |       0.2878 |       0.2221 |       89.06% |       93.40% |       0.0100 |
|            5 |          550 |        27.28 |       0.1009 |       0.1948 |       96.88% |       93.70% |       0.0100 |
|            5 |          600 |        30.00 |       0.1538 |       0.1959 |       93.75% |       93.90% |       0.0100 |
|            6 |          650 |        32.61 |       0.1448 |       0.1920 |       93.75% |       93.90% |       0.0020 |
|            6 |          700 |        35.12 |       0.0484 |       0.1780 |       98.44% |       94.60% |       0.0020 |
|            6 |          750 |        37.66 |       0.1073 |       0.1725 |       96.88% |       94.40% |       0.0020 |
|            7 |          800 |        40.10 |       0.0695 |       0.1724 |       98.44% |       95.00% |       0.0020 |
|            7 |          850 |        42.50 |       0.1090 |       0.1669 |       93.75% |       95.20% |       0.0020 |
|            8 |          900 |        44.95 |       0.0707 |       0.1676 |       98.44% |       94.50% |       0.0020 |
|            8 |          950 |        47.47 |       0.0379 |       0.1721 |       98.44% |       94.90% |       0.0020 |
|            8 |         1000 |        50.10 |       0.0983 |       0.1667 |       96.88% |       95.00% |       0.0020 |
|            9 |         1050 |        52.57 |       0.0626 |       0.1671 |       98.44% |       95.00% |       0.0020 |
|            9 |         1100 |        55.15 |       0.0939 |       0.1620 |       96.88% |       95.80% |       0.0020 |
|           10 |         1150 |        57.80 |       0.0588 |       0.1631 |       98.44% |       94.60% |       0.0020 |
|           10 |         1200 |        60.27 |       0.0340 |       0.1696 |      100.00% |       94.80% |       0.0020 |
|           10 |         1250 |        62.77 |       0.0864 |       0.1631 |       98.44% |       95.20% |       0.0020 |
|           11 |         1300 |        65.26 |       0.0567 |       0.1605 |       98.44% |       94.90% |       0.0004 |
|           11 |         1350 |        67.94 |       0.0822 |       0.1610 |       98.44% |       94.90% |       0.0004 |
|           12 |         1400 |        70.40 |       0.0549 |       0.1600 |      100.00% |       95.00% |       0.0004 |
|           12 |         1450 |        72.92 |       0.0370 |       0.1599 |       98.44% |       95.10% |       0.0004 |
|           12 |         1500 |        75.42 |       0.0816 |       0.1609 |       96.88% |       95.30% |       0.0004 |
|           13 |         1550 |        77.92 |       0.0540 |       0.1591 |       98.44% |       95.00% |       0.0004 |
|           13 |         1600 |        80.47 |       0.0821 |       0.1597 |       98.44% |       95.40% |       0.0004 |
|           14 |         1650 |        82.93 |       0.0528 |       0.1587 |      100.00% |       95.20% |       0.0004 |
|           14 |         1700 |        85.53 |       0.0362 |       0.1588 |       98.44% |       95.40% |       0.0004 |
|           14 |         1750 |        88.18 |       0.0793 |       0.1598 |       98.44% |       95.40% |       0.0004 |
|           15 |         1800 |        90.54 |       0.0517 |       0.1580 |       98.44% |       95.00% |       0.0004 |
|           15 |         1850 |        93.01 |       0.0796 |       0.1587 |       98.44% |       95.40% |       0.0004 |
|           16 |         1900 |        95.48 |       0.0523 |       0.1583 |      100.00% |       95.30% |     8.00e-05 |
|           16 |         1950 |        97.95 |       0.0330 |       0.1578 |       98.44% |       95.30% |     8.00e-05 |
|           16 |         2000 |       100.49 |       0.0727 |       0.1581 |       98.44% |       95.20% |     8.00e-05 |
|           17 |         2050 |       103.15 |       0.0506 |       0.1576 |       98.44% |       95.30% |     8.00e-05 |
|           17 |         2100 |       105.82 |       0.0751 |       0.1578 |       98.44% |       95.30% |     8.00e-05 |
|           18 |         2150 |       108.33 |       0.0518 |       0.1578 |      100.00% |       95.10% |     8.00e-05 |
|           18 |         2200 |       110.86 |       0.0335 |       0.1576 |       98.44% |       95.30% |     8.00e-05 |
|           18 |         2250 |       113.39 |       0.0726 |       0.1579 |       98.44% |       95.20% |     8.00e-05 |
|           19 |         2300 |       115.83 |       0.0498 |       0.1574 |       98.44% |       95.30% |     8.00e-05 |
|           19 |         2350 |       118.36 |       0.0747 |       0.1576 |       98.44% |       95.30% |     8.00e-05 |
|           20 |         2400 |       120.85 |       0.0514 |       0.1576 |      100.00% |       95.20% |     8.00e-05 |
|           20 |         2450 |       123.37 |       0.0335 |       0.1574 |       98.44% |       95.30% |     8.00e-05 |
|           20 |         2500 |       126.03 |       0.0722 |       0.1577 |       98.44% |       95.20% |     8.00e-05 |
|=======================================================================================================================|
Training on single CPU.
Initializing image normalization.
|=======================================================================================================================|
|     Epoch    |   Iteration  | Time Elapsed |  Mini-batch  |  Validation  |  Mini-batch  |  Validation  | Base Learning|
|              |              |  (seconds)   |     Loss     |     Loss     |   Accuracy   |   Accuracy   |     Rate     |
|=======================================================================================================================|
|            1 |            1 |         0.08 |       2.2353 |       2.2046 |       18.75% |       28.70% |       0.0100 |
|            1 |           50 |         1.25 |       0.4825 |       0.3917 |       81.25% |       88.70% |       0.0100 |
|            1 |          100 |         2.41 |       0.2041 |       0.2850 |       95.31% |       91.80% |       0.0100 |
|            2 |          150 |         3.57 |       0.4532 |       0.2747 |       87.50% |       91.60% |       0.0100 |
|            2 |          200 |         4.69 |       0.1699 |       0.2505 |       90.62% |       93.50% |       0.0100 |
|            2 |          250 |         5.82 |       0.3088 |       0.2235 |       90.62% |       93.40% |       0.0100 |
|            3 |          300 |         7.00 |       0.0989 |       0.2119 |       96.88% |       94.40% |       0.0100 |
|            3 |          350 |         8.13 |       0.1125 |       0.1890 |       96.88% |       95.00% |       0.0100 |
|            4 |          400 |         9.31 |       0.2392 |       0.2016 |       93.75% |       94.10% |       0.0100 |
|            4 |          450 |        10.46 |       0.0771 |       0.2035 |       96.88% |       94.00% |       0.0100 |
|            4 |          500 |        11.62 |       0.1319 |       0.1862 |       95.31% |       94.80% |       0.0100 |
|            5 |          550 |        12.78 |       0.0535 |       0.1974 |       98.44% |       94.60% |       0.0100 |
|            5 |          600 |        13.91 |       0.0703 |       0.1788 |       98.44% |       95.00% |       0.0100 |
|            6 |          650 |        15.07 |       0.1154 |       0.1876 |       96.88% |       94.00% |       0.0020 |
|            6 |          700 |        16.36 |       0.0424 |       0.1713 |       98.44% |       95.10% |       0.0020 |
|            6 |          750 |        17.82 |       0.0246 |       0.1649 |      100.00% |       95.40% |       0.0020 |
|            7 |          800 |        19.28 |       0.0481 |       0.1716 |       98.44% |       95.10% |       0.0020 |
|            7 |          850 |        20.78 |       0.0416 |       0.1670 |       98.44% |       95.40% |       0.0020 |
|            8 |          900 |        22.02 |       0.1007 |       0.1719 |       96.88% |       94.80% |       0.0020 |
|            8 |          950 |        23.31 |       0.0368 |       0.1697 |       98.44% |       95.10% |       0.0020 |
|            8 |         1000 |        24.51 |       0.0235 |       0.1649 |      100.00% |       95.20% |       0.0020 |
|            9 |         1050 |        25.69 |       0.0318 |       0.1718 |      100.00% |       95.60% |       0.0020 |
|            9 |         1100 |        26.78 |       0.0344 |       0.1676 |      100.00% |       95.20% |       0.0020 |
|           10 |         1150 |        27.91 |       0.0782 |       0.1731 |       98.44% |       94.90% |       0.0020 |
|           10 |         1200 |        29.01 |       0.0306 |       0.1714 |      100.00% |       95.00% |       0.0020 |
|           10 |         1250 |        30.20 |       0.0210 |       0.1666 |      100.00% |       95.30% |       0.0020 |
|           11 |         1300 |        31.46 |       0.0191 |       0.1695 |      100.00% |       95.30% |       0.0004 |
|           11 |         1350 |        32.61 |       0.0261 |       0.1683 |      100.00% |       95.20% |       0.0004 |
|           12 |         1400 |        33.71 |       0.0655 |       0.1681 |       98.44% |       95.10% |       0.0004 |
|           12 |         1450 |        34.78 |       0.0284 |       0.1693 |      100.00% |       95.40% |       0.0004 |
|           12 |         1500 |        36.04 |       0.0183 |       0.1674 |      100.00% |       95.00% |       0.0004 |
|=======================================================================================================================|
Training on single CPU.
Initializing image normalization.
|=======================================================================================================================|
|     Epoch    |   Iteration  | Time Elapsed |  Mini-batch  |  Validation  |  Mini-batch  |  Validation  | Base Learning|
|              |              |  (seconds)   |     Loss     |     Loss     |   Accuracy   |   Accuracy   |     Rate     |
|=======================================================================================================================|
|            1 |            1 |         0.66 |       2.5802 |       2.5356 |        6.25% |       17.20% |       0.0100 |
|            1 |           50 |        30.73 |       0.2747 |       0.3463 |       90.62% |       91.20% |       0.0100 |
|            1 |          100 |        63.26 |       0.3074 |       0.1965 |       93.75% |       95.20% |       0.0100 |
|            2 |          150 |        93.97 |       0.0767 |       0.1656 |       98.44% |       95.60% |       0.0100 |
|            2 |          200 |       125.34 |       0.0949 |       0.1528 |       96.88% |       95.80% |       0.0100 |
|            2 |          250 |       157.40 |       0.0391 |       0.1622 |       98.44% |       95.90% |       0.0100 |
|            3 |          300 |       188.15 |       0.0493 |       0.1392 |       98.44% |       96.00% |       0.0100 |
|            3 |          350 |       218.25 |       0.0984 |       0.1427 |       98.44% |       96.10% |       0.0100 |
|            4 |          400 |       249.11 |       0.0303 |       0.1309 |      100.00% |       96.40% |       0.0100 |
|            4 |          450 |       280.66 |       0.0315 |       0.1196 |      100.00% |       96.90% |       0.0100 |
|            4 |          500 |       311.21 |       0.0122 |       0.1318 |      100.00% |       96.60% |       0.0100 |
|            5 |          550 |       342.10 |       0.0280 |       0.1277 |      100.00% |       96.60% |       0.0100 |
|            5 |          600 |       373.00 |       0.0453 |       0.1286 |       98.44% |       96.70% |       0.0100 |
|            6 |          650 |       406.10 |       0.0277 |       0.1486 |      100.00% |       96.20% |       0.0020 |
|            6 |          700 |       436.80 |       0.0307 |       0.1215 |       98.44% |       97.20% |       0.0020 |
|            6 |          750 |       467.48 |       0.0077 |       0.1166 |      100.00% |       97.40% |       0.0020 |
|            7 |          800 |       498.93 |       0.0114 |       0.1188 |      100.00% |       96.70% |       0.0020 |
|            7 |          850 |       534.36 |       0.0074 |       0.1128 |      100.00% |       97.30% |       0.0020 |
|            8 |          900 |       567.01 |       0.0182 |       0.1157 |       98.44% |       96.80% |       0.0020 |
|            8 |          950 |       599.73 |       0.0204 |       0.1151 |      100.00% |       97.00% |       0.0020 |
|            8 |         1000 |       631.46 |       0.0072 |       0.1127 |      100.00% |       97.30% |       0.0020 |
|            9 |         1050 |       664.34 |       0.0082 |       0.1155 |      100.00% |       96.70% |       0.0020 |
|            9 |         1100 |       696.99 |       0.0073 |       0.1117 |      100.00% |       97.40% |       0.0020 |
|           10 |         1150 |       729.67 |       0.0140 |       0.1143 |      100.00% |       96.70% |       0.0020 |
|           10 |         1200 |       761.99 |       0.0166 |       0.1142 |      100.00% |       97.00% |       0.0020 |
|           10 |         1250 |       791.07 |       0.0064 |       0.1121 |      100.00% |       97.30% |       0.0020 |
|           11 |         1300 |       820.02 |       0.0058 |       0.1124 |      100.00% |       97.30% |       0.0004 |
|           11 |         1350 |       852.20 |       0.0059 |       0.1123 |      100.00% |       97.30% |       0.0004 |
|           12 |         1400 |       884.74 |       0.0118 |       0.1127 |      100.00% |       97.30% |       0.0004 |
|           12 |         1450 |       917.97 |       0.0135 |       0.1129 |      100.00% |       97.10% |       0.0004 |
|           12 |         1500 |       953.31 |       0.0066 |       0.1126 |      100.00% |       97.30% |       0.0004 |
|           13 |         1550 |       984.18 |       0.0057 |       0.1129 |      100.00% |       97.10% |       0.0004 |
|           13 |         1600 |      1016.14 |       0.0061 |       0.1126 |      100.00% |       97.20% |       0.0004 |
|=======================================================================================================================|
 
 ----------------------------- 
          MNIST - CNN          
 ----------------------------- 
 
    CNN_Architecture    Error_int    Error_test
    ________________    _________    __________

    1                   0.025625     0.055     
    2                   0.020375     0.049     
    3                   0.002125     0.045     
    4                   0.001625     0.031     

 
 
 Training:        notMNIST - CNN        
 
Training on single CPU.
Initializing image normalization.
|=======================================================================================================================|
|     Epoch    |   Iteration  | Time Elapsed |  Mini-batch  |  Validation  |  Mini-batch  |  Validation  | Base Learning|
|              |              |  (seconds)   |     Loss     |     Loss     |   Accuracy   |   Accuracy   |     Rate     |
|=======================================================================================================================|
|            1 |            1 |         0.04 |       2.3042 |       2.3027 |       17.19% |       10.60% |       0.0100 |
|            1 |           50 |         1.47 |       0.6220 |       4.1856 |       89.06% |        9.00% |       0.0100 |
|            1 |          100 |         2.91 |       0.3960 |       3.5908 |       87.50% |        8.70% |       0.0100 |
|            2 |          150 |         4.28 |       0.5318 |       3.2975 |       89.06% |        9.10% |       0.0100 |
|            2 |          200 |         5.74 |       0.4448 |       3.4896 |       84.38% |       10.80% |       0.0100 |
|            2 |          250 |         7.23 |       0.4183 |       3.6401 |       90.62% |       10.00% |       0.0100 |
|            3 |          300 |         8.69 |       0.3133 |       3.2172 |       92.19% |        9.10% |       0.0100 |
|            3 |          350 |        10.18 |       0.2938 |       3.5593 |       95.31% |        8.40% |       0.0100 |
|            4 |          400 |        11.67 |       0.4704 |       3.6052 |       90.62% |       10.10% |       0.0100 |
|            4 |          450 |        13.05 |       0.3325 |       3.8653 |       92.19% |       10.00% |       0.0100 |
|            4 |          500 |        14.50 |       0.3605 |       3.9890 |       92.19% |        9.80% |       0.0100 |
|=======================================================================================================================|
Training on single CPU.
Initializing image normalization.
|=======================================================================================================================|
|     Epoch    |   Iteration  | Time Elapsed |  Mini-batch  |  Validation  |  Mini-batch  |  Validation  | Base Learning|
|              |              |  (seconds)   |     Loss     |     Loss     |   Accuracy   |   Accuracy   |     Rate     |
|=======================================================================================================================|
|            1 |            1 |         0.04 |       2.3026 |       2.3026 |        4.69% |        9.60% |       0.0100 |
|            1 |           50 |         2.50 |       2.2995 |       2.3038 |        9.38% |        9.80% |       0.0100 |
|            1 |          100 |         5.00 |       2.1962 |       2.3149 |       12.50% |       10.00% |       0.0100 |
|            2 |          150 |         7.49 |       0.6255 |       4.0528 |       81.25% |        8.60% |       0.0100 |
|            2 |          200 |        10.25 |       0.5433 |       3.1091 |       81.25% |       10.30% |       0.0100 |
|            2 |          250 |        13.18 |       0.2650 |       2.9752 |       95.31% |       10.00% |       0.0100 |
|            3 |          300 |        15.57 |       0.3304 |       3.2140 |       87.50% |       10.50% |       0.0100 |
|            3 |          350 |        18.01 |       0.2141 |       2.8975 |       92.19% |        9.00% |       0.0100 |
|            4 |          400 |        20.39 |       0.2548 |       3.2994 |       89.06% |        9.90% |       0.0100 |
|            4 |          450 |        22.75 |       0.3981 |       3.0297 |       89.06% |       10.30% |       0.0100 |
|            4 |          500 |        25.11 |       0.1719 |       3.1167 |       96.88% |       10.40% |       0.0100 |
|=======================================================================================================================|
Training on single CPU.
Initializing image normalization.
|=======================================================================================================================|
|     Epoch    |   Iteration  | Time Elapsed |  Mini-batch  |  Validation  |  Mini-batch  |  Validation  | Base Learning|
|              |              |  (seconds)   |     Loss     |     Loss     |   Accuracy   |   Accuracy   |     Rate     |
|=======================================================================================================================|
|            1 |            1 |         0.03 |       2.3906 |       2.4103 |        3.12% |       10.30% |       0.0100 |
|            1 |           50 |         1.35 |       0.3561 |       5.1714 |       87.50% |       10.20% |       0.0100 |
|            1 |          100 |         2.52 |       0.7546 |       4.0991 |       81.25% |       10.20% |       0.0100 |
|            2 |          150 |         3.56 |       0.4179 |       4.3880 |       87.50% |       11.20% |       0.0100 |
|            2 |          200 |         4.59 |       0.3941 |       4.9208 |       84.38% |       10.40% |       0.0100 |
|            2 |          250 |         5.63 |       0.2707 |       4.2438 |       92.19% |       10.70% |       0.0100 |
|            3 |          300 |         6.71 |       0.1992 |       4.1951 |       95.31% |       11.30% |       0.0100 |
|            3 |          350 |         7.81 |       0.4918 |       4.5949 |       82.81% |       11.00% |       0.0100 |
|            4 |          400 |         8.94 |       0.1591 |       4.4725 |       95.31% |       10.10% |       0.0100 |
|            4 |          450 |        10.05 |       0.2565 |       4.8830 |       95.31% |       10.60% |       0.0100 |
|            4 |          500 |        11.11 |       0.1793 |       4.8804 |       96.88% |        9.70% |       0.0100 |
|=======================================================================================================================|
Training on single CPU.
Initializing image normalization.
|=======================================================================================================================|
|     Epoch    |   Iteration  | Time Elapsed |  Mini-batch  |  Validation  |  Mini-batch  |  Validation  | Base Learning|
|              |              |  (seconds)   |     Loss     |     Loss     |   Accuracy   |   Accuracy   |     Rate     |
|=======================================================================================================================|
|            1 |            1 |         0.58 |       2.7059 |       2.6793 |        7.81% |       10.10% |       0.0100 |
|            1 |           50 |        32.95 |       0.4067 |       4.9704 |       90.62% |       10.10% |       0.0100 |
|            1 |          100 |        65.09 |       0.7523 |       3.6122 |       82.81% |        9.70% |       0.0100 |
|            2 |          150 |        99.57 |       0.2342 |       3.6758 |       95.31% |        9.20% |       0.0100 |
|            2 |          200 |       134.97 |       0.2291 |       4.0732 |       93.75% |        9.50% |       0.0100 |
|            2 |          250 |       165.83 |       0.5376 |       3.8039 |       85.94% |        9.60% |       0.0100 |
|            3 |          300 |       195.64 |       0.2326 |       4.1147 |       93.75% |        9.80% |       0.0100 |
|            3 |          350 |       227.68 |       0.3877 |       3.9305 |       92.19% |       10.00% |       0.0100 |
|            4 |          400 |       258.04 |       0.1017 |       3.9774 |       98.44% |        9.40% |       0.0100 |
|            4 |          450 |       289.33 |       0.1760 |       4.5791 |       96.88% |        8.90% |       0.0100 |
|            4 |          500 |       320.46 |       0.3707 |       4.4036 |       89.06% |       10.30% |       0.0100 |
|=======================================================================================================================|
 
 ----------------------------- 
         notMNIST - CNN        
 ----------------------------- 
 
    CNN_Architecture    Error_int    Error_test
    ________________    _________    __________

    1                    0.08275     0.112     
    2                    0.08125     0.108     
    3                   0.044875     0.099     
    4                     0.0415     0.088     

 
 
 Training:     Fashion MNIST - CNN      
 
Training on single CPU.
Initializing image normalization.
|=======================================================================================================================|
|     Epoch    |   Iteration  | Time Elapsed |  Mini-batch  |  Validation  |  Mini-batch  |  Validation  | Base Learning|
|              |              |  (seconds)   |     Loss     |     Loss     |   Accuracy   |   Accuracy   |     Rate     |
|=======================================================================================================================|
|            1 |            1 |         0.06 |       2.3031 |       2.3027 |       14.06% |       10.20% |       0.0100 |
|            1 |           50 |         1.44 |       0.9038 |       3.7357 |       64.06% |       10.50% |       0.0100 |
|            1 |          100 |         2.80 |       0.6194 |       3.3265 |       79.69% |       10.10% |       0.0100 |
|            2 |          150 |         4.23 |       0.6616 |       3.5174 |       78.12% |       10.10% |       0.0100 |
|            2 |          200 |         5.63 |       0.6065 |       3.9110 |       75.00% |        9.80% |       0.0100 |
|            2 |          250 |         7.03 |       0.5618 |       4.0651 |       81.25% |        9.40% |       0.0100 |
|            3 |          300 |         8.42 |       0.5386 |       4.4965 |       78.12% |        8.90% |       0.0100 |
|            3 |          350 |         9.73 |       0.4502 |       4.3524 |       82.81% |        9.60% |       0.0100 |
|            4 |          400 |        11.10 |       0.5806 |       4.5882 |       79.69% |        9.50% |       0.0100 |
|            4 |          450 |        12.38 |       0.4631 |       4.6192 |       84.38% |        9.40% |       0.0100 |
|            4 |          500 |        13.81 |       0.5189 |       4.7135 |       82.81% |       10.10% |       0.0100 |
|=======================================================================================================================|
Training on single CPU.
Initializing image normalization.
|=======================================================================================================================|
|     Epoch    |   Iteration  | Time Elapsed |  Mini-batch  |  Validation  |  Mini-batch  |  Validation  | Base Learning|
|              |              |  (seconds)   |     Loss     |     Loss     |   Accuracy   |   Accuracy   |     Rate     |
|=======================================================================================================================|
|            1 |            1 |         0.05 |       2.3026 |       2.3026 |        7.81% |        9.70% |       0.0100 |
|            1 |           50 |         2.40 |       2.3036 |       2.3026 |       20.31% |       11.30% |       0.0100 |
|            1 |          100 |         4.73 |       2.2842 |       2.3018 |       46.88% |       10.80% |       0.0100 |
|            2 |          150 |         7.08 |       1.0674 |       3.3124 |       56.25% |        9.80% |       0.0100 |
|            2 |          200 |         9.44 |       0.7344 |       3.4010 |       70.31% |       10.20% |       0.0100 |
|            2 |          250 |        11.83 |       0.7812 |       3.4454 |       70.31% |        8.80% |       0.0100 |
|            3 |          300 |        14.17 |       0.5998 |       3.6456 |       78.12% |        8.20% |       0.0100 |
|            3 |          350 |        16.71 |       0.5198 |       3.8239 |       76.56% |        8.90% |       0.0100 |
|            4 |          400 |        19.28 |       0.8356 |       4.1685 |       73.44% |        8.50% |       0.0100 |
|            4 |          450 |        21.90 |       0.5249 |       3.7246 |       79.69% |        9.80% |       0.0100 |
|            4 |          500 |        24.55 |       0.6068 |       4.0720 |       78.12% |        8.80% |       0.0100 |
|            5 |          550 |        27.11 |       0.5270 |       3.9703 |       79.69% |        9.10% |       0.0100 |
|            5 |          600 |        29.63 |       0.4462 |       4.3515 |       78.12% |        9.00% |       0.0100 |
|=======================================================================================================================|
Training on single CPU.
Initializing image normalization.
|=======================================================================================================================|
|     Epoch    |   Iteration  | Time Elapsed |  Mini-batch  |  Validation  |  Mini-batch  |  Validation  | Base Learning|
|              |              |  (seconds)   |     Loss     |     Loss     |   Accuracy   |   Accuracy   |     Rate     |
|=======================================================================================================================|
|            1 |            1 |         0.03 |       2.3880 |       2.3649 |       10.94% |       10.30% |       0.0100 |
|            1 |           50 |         1.06 |       0.6196 |       3.8374 |       73.44% |       10.20% |       0.0100 |
|            1 |          100 |         2.12 |       0.5076 |       3.7373 |       84.38% |        9.00% |       0.0100 |
|            2 |          150 |         3.18 |       0.4316 |       3.8205 |       84.38% |        9.30% |       0.0100 |
|            2 |          200 |         4.25 |       0.2895 |       4.3271 |       90.62% |        9.50% |       0.0100 |
|            2 |          250 |         5.31 |       0.4734 |       4.0083 |       82.81% |        8.80% |       0.0100 |
|            3 |          300 |         6.37 |       0.2805 |       4.4044 |       90.62% |        8.60% |       0.0100 |
|            3 |          350 |         7.43 |       0.3610 |       4.4342 |       85.94% |        9.50% |       0.0100 |
|            4 |          400 |         8.50 |       0.3718 |       4.3900 |       89.06% |       10.00% |       0.0100 |
|            4 |          450 |         9.56 |       0.1872 |       4.8805 |       93.75% |        9.10% |       0.0100 |
|            4 |          500 |        10.62 |       0.4567 |       4.6696 |       84.38% |        9.50% |       0.0100 |
|=======================================================================================================================|
Training on single CPU.
Initializing image normalization.
|=======================================================================================================================|
|     Epoch    |   Iteration  | Time Elapsed |  Mini-batch  |  Validation  |  Mini-batch  |  Validation  | Base Learning|
|              |              |  (seconds)   |     Loss     |     Loss     |   Accuracy   |   Accuracy   |     Rate     |
|=======================================================================================================================|
|            1 |            1 |         0.55 |       2.4615 |       3.2398 |       12.50% |        8.60% |       0.0100 |
|            1 |           50 |        30.05 |       0.5747 |       3.6237 |       71.88% |       10.60% |       0.0100 |
|            1 |          100 |        61.03 |       0.5475 |       3.5120 |       78.12% |       10.00% |       0.0100 |
|            2 |          150 |        91.81 |       0.2194 |       4.0665 |       98.44% |        8.80% |       0.0100 |
|            2 |          200 |       123.06 |       0.4672 |       4.2925 |       76.56% |        9.00% |       0.0100 |
|            2 |          250 |       154.77 |       0.3629 |       4.1194 |       84.38% |        9.50% |       0.0100 |
|            3 |          300 |       186.45 |       0.3159 |       4.0869 |       87.50% |       10.00% |       0.0100 |
|            3 |          350 |       218.34 |       0.4645 |       3.9924 |       78.12% |        9.10% |       0.0100 |
|            4 |          400 |       248.78 |       0.1355 |       4.2831 |       98.44% |        8.80% |       0.0100 |
|            4 |          450 |       279.60 |       0.3183 |       4.5129 |       87.50% |        9.20% |       0.0100 |
|            4 |          500 |       311.72 |       0.3140 |       4.4189 |       89.06% |        8.80% |       0.0100 |
|=======================================================================================================================|
 
 ----------------------------- 
      Fashion MNIST - CNN      
 ----------------------------- 
 
    CNN_Architecture    Error_int    Error_test
    ________________    _________    __________

    1                   0.16287      0.179     
    2                   0.16225      0.168     
    3                    0.1035      0.148     
    4                   0.10475      0.144     

 
>> 